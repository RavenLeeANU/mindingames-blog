---
title: 智能体在游戏中的应用
date: '2023-12-09'
tags: ['AI Agent', 'LLM', '游戏']
draft: false
summary: '.'
---

# 一、研究背景

## 智能体

对智能体(Agent)的研究由来已久。

从战国时代的墨家机关术的记载与传说，再到近代的智能机器人的兴起，可见人类自古以来都在追求类人甚至是超越人类的造物。通过对机械或软件等进行程序化的设计以达到帮助人类从事工作的目的，而更加智能的程序则需要能够**感知环境**、**自主决策**和**采取措施。**

近代以来，计算机的迅速发展使得 AI(artificial intelligence)成为可能。智能体的发展也经历了符号化智能体(Symbolic Agents)，反应式智能体(Reactive agents)，基于强化学习的智能体(Reinforcement learning-based agents)，基于迁移学习和元学习的智能体(Agents with transfer learning and meta learning)，以及目前火热的基于大模型的 Agent(Large language model-based agents)。

**符号化智能体**

早期的符号化智能体(Symbolic Agents)经常基于某类规则和文字进行判断和识别人的意图。例如基于知识的专家系统，通过预设的情境和规则进行条件判断和系统诊断也能够部分达成目的，但缺点是对例外的输入和不在预设范围内的情境无法做出正确的判断和反馈。

符号化的智能体就像是一个呆板的图书馆管理员，只有你能准确报出书名，他才会给你答案。

**反应式智能体**

反应式智能体通过预设的感知系统，通常是传感器等组件来收集和处理环境的变化，最常见的例如家用扫地机器人，当他的传感器检测到存在避障物时会选择主动避障，选择新的路径并继续收集检测信息，这种行为被称作是感知-行动循环（**sense-act loop）.**

这类智能体就像是单细胞生物一般，具有一定的感知环境、趋利避害的能力，但是所能做出的反馈也相当有限。

**强化学习的智能体**

强化学习智能的兴起真正使人类开始正视人工智能的能力会超越人类自身这一事实。最有代表性的事件使有强化学习训练的围棋人工智能 AlphaGo 击败了围棋世界冠军李世石，从而证明了强化学习在处理单一任务上是可以完胜人类，此后在多种不同任务上也印证了这一观点。但强化学习也存在明显的问题，在单一任务上是天才而其他任务则成为了白痴。

**基于迁移学习和元学习的智能体**

通过深度神经网络和基于元学习的智能体可以在不同任务上进行迁移，将相似的经验和知识转化为可以适应新任务的能力。基于这样的能力人们开始感觉在实现**AGI(全人工智能)**的目标上越来越近。

**基于大模型的 Agent**

而近两年随着 GPT 的崛起，使得大预言模型成为了 21 世纪最重要的技术进步之一。大语言模型通过使用海量的文本内容训练逐渐拥有理解人的对话意图并给出合理恢复的能力。人可以通过自然语言的提示来让大模型写代码，编故事或完成各类其他任务。而通过大模型驱动的 Agent 则是目前最有可能的接近全人工智能的。

## 基于 LLM 的智能体基础架构

根据智能体的定义和在近年来的 LLM 实践，逐渐总结出了一套行之有效的基于 LLM 的智能体驱动框架。比较有代表性的工作是斯坦福的西部小镇（Generative Agents: Interactive Simulacra of Human Behavior）。

![](/static/images/k1/U455b24faoV6taxYnhGcCdMdnYc.png)

这篇文章中设定一个拥有居民房间、学校等各种地点的小镇作为仿真环境，通过使用大语言模型驱动角色在适应环境并在小镇上生活。角色没有预先设定的事件和触发机制，而是单纯通过使用大语言模型设计了具备规划、记忆、反思和交互等能力的智能体，让智能体仿佛真的生活在故事设定的场景中一般。

Demo 可以在此体验：[https://reverie.herokuapp.com/UIST_Demo/](https://reverie.herokuapp.com/UIST_Demo/)

实际上通用智能体的发展伴随着 LLM 的发展逐渐兴旺，在不断实践和归纳中，基于智能体的最佳实践的基础架构逐渐清晰，并且以惊人的速度在飞快发展和扩充，未来智能体将和人类一样作为活跃在现实世界中的一员。

![](/static/images/k1/KDmObMVWAoreoAxVQkKczxCknIJ.png)

根据智能体基础定义，其基本架构可以抽象成三个主要的能力，即**感知(Perception)**、**行为(Behavior)**和**大脑(Brain)。**

**感知**

感知能力包括通过各种传感器、用户输入等处理来自环境的信息。由于真实环境的信息纷繁复杂，有文本、用户事件、音视频等多种多样的格式，因此具备多模态的感知能力和联合数据的分析处理能力对于智能体的决策和理解至关重要。

**大脑**

人类的大脑结构非常复杂，庞大的神经元支持了人类处理从低级的神经活动反馈到高级的记忆、决策、创意等思维活动。使用提示词工程技术(Prompt Engineering) ，RAG，SFT 等技术可以帮助大模型更好地理解输入的信息。设计大脑对记忆管理，思考逻辑等功能以逼近人类思维活动的能力。

**行为**

将大脑产生的逻辑决策转化为影响环境的输出，智能体的行为能力主要体现在对工具的驱动上。例如通过格式化的输出，例如标准化 API 参数，codebook 等多样化的内容来驱动执行机构或工具进行工作。

![](/static/images/k1/Eu25b8FDRovnjUxpx3rcnQTWnFh.png)

## 游戏中的智能体的意义

游戏本质上是构建了一个规则化的真实世界，相对于智能体来说，理解游戏与理解真实世界在本质上并无二致。几十年来游戏产业的发展，使得游戏的工业化水平越来越成熟。具有复杂交互规则、真实物理环境的 AAA 游戏层出不穷，游戏场景对于智能体来说是极佳的仿真环境，通过学习相似的能力和决策方式，这些能力可以迁移至真实世界中以参与构建能够投入实际生产生活的具身智能体。

另一方面，游戏本身的体验长久以来得益于游戏开发者、艺术家们的设计和创造。但是人工设计始终无法穷尽各种体验的可能，因此游戏中存在着大量的约束和重复的内容。使用生成式智能体参与到游戏的角色扮演、内容生产可以为玩家带来独一无二的用户体验，极大增加游戏的可玩性和用户粘性。

# **二、AI + 游戏现状**

**AI NPC 设计**

即使是传统游戏中也不乏存在大量的 AI 设计，例如动作游戏中的 Boss 行为，模拟经营游戏中的村民，甚至是关卡的引导员等。不管是 AAA 游戏还是独立游戏，游戏产品中对 AI 几乎构成了整个游戏的核心体验。

生成式智能体最令人激动的是可以基于输入产出源源不断的新的内容且不会拘泥于游戏的载体或者是形式，即使是文字游戏，泥巴游戏都能够赋予无穷的变化。

如果说对话也是一种游戏，character.ai 无疑是非常成功的产品。它通过 LLM 提供了丰富多样的具备人设的智能体，你可以与这样的智能体进行对话，询问它关于故事的某些情节或者对某人的看法，或者通过对话进行文字冒险的游戏，甚至是谈恋爱等等。

![](/static/images/k1/BeIybROvKoj7bTxP8JYcL17vnEe.png)

而在视频游戏中使用生成式智能体则拥有更多想象力。

斯坦福西部小镇已经给了开发者们很多的启发，通过通用的提示词技能如 CoT、ReAct 开发者就已经能够构建具备丰富反馈的智能体角色了。例如，Suckup 和病娇猫娘这样的游戏。游戏中 AI 智能体可以根据玩家的对话做出自己的行为反馈，例如让你进屋，或者拿着刀追逐你。

![](/static/images/k1/NQLsbSRz7okCllxrVe2cL5zVnwb.png)

![](/static/images/k1/UD4FbAzjaoRAuqxzvJBcpHwlnDh.png)

同样我们可以为整个 NPC 构造更加真实的形象和体验。例如微软、英伟达等大厂和一众如 inworld 这样的优秀创业公司就在做这样的事情。

![](/static/images/k1/E8mFb71AGo3mcGx1gHzcXBa2nDf.png)

让 NPC 更像人关注于提升视觉、听觉等的表现力，通过构建复杂的多模态交互技术，让 NPC 具备生动的表情、动作、不同情绪的语音语调等等。另外这些驱动反馈需要在很短的时间内得到执行，否则将会极大地影响用户的体验，这对智能体 Action 部分的设计提出了很高的要求。

另外作为产品来说，平衡大模型的调用成本和允许用户在交互中犯错和恶作剧并把用户引导回原有的故事中也是需要开发者深思熟虑的事情。

**AI 规则器设计**

除了 NPC 之外，生成式 AI 同样可以用于对规则器的构建。这一部分虽然不容易被玩家察觉但也确至关重要。传统游戏中基于系统逻辑的规则开发者们早已驾轻就熟，而使用生成式规则器的优势也非常明显：处理模糊的规则和产生新的规则。

同样在文字游戏的 AI 实践中，例如 AI Dougeon 中 AI 扮演的 DM 则可以代替人类给我们提供非常丰富的选择多样性。这种对于不确定输入的处理可以在具有开放世界游戏中为玩家带来更多的探索乐趣和体验。

![](/static/images/k1/KRJQbzFcVo75C3x88s5cNXCLnRc.png)

然而如何产生与人类设计者一样具有跌宕起伏的冒险故事和逻辑自洽的体验内容依然是一个具有挑战性的内容。应用在有限资产和确定系统的环境下的生成式规则器如何更好地理解系统的边界和内容的有限性中产生合理的组合同样也非常需要大模型自身减少幻觉并充分理解游戏设计者的规则。也许伴随着各类 AI 资产生成技术的逐渐成熟落地，实时地在游戏中创建新的游戏而并非使用人工预设的模板内容也将成为可能。

PS: 使用人工 +AI 生成的游戏目前可能是一个比较可行的解，通过用户给出输入，由 AI 构建游戏场景 + 逻辑，再由人工进行修改，完成后 build 成完整的游戏。这种离线生产的内容短期来看也可以实现，例如 buildbox 正在制作基于 AI 生成的规则化引擎，还尚处于较为初级的阶段。而使用 AI+PCG 方式生产游戏也存在，但这就是另一个故事了，这里再次不做展开。

# **三、AI 智能体在游戏开发中的设计实践**

开发 AI+ 游戏需要时刻清楚我们的目标，第一原则就是需要在设计时搞清系统的边界是什么。如果项目的系统是围绕着 LLM 的输入输出构建的，例如前文提到的地牢类型的游戏或者是基于角色扮演和对话的逻辑，那开发的中心将围绕在提示词模板的开发和驱动 token 的构建上。这通常适合于开发单一玩法的系统。

例如，我们在开发对话游戏玩法时，设计了“根据你激怒 NPC 的次数” 作为游戏胜利的目标。那么当你在提示词设计时需要考虑在输入对话时考虑角色的情绪的判定结果的输出，提示词可以是：

并给出 few-shots：

```
'{情绪:1}（微笑着点头）你叫什么名字？',
'{情绪:2}（张开双臂，跳跃着跑来）哇，好开心能见到你啊！',
'{情绪:2}（露出笑容，双手抱拳）新年好啊，恭喜发财！',
'{情绪:5}（右手握拳，坚定地看着对方）加油，相信你一定可以做到的
```

这样做的目的是便于在流式返回时同时输出内容和判定结果，这需要额外的 parser 来解析定义的情绪 token。当然也可以采用多次调用的方式，即在每次返回语句后再次进行判定，获得情绪的结果：

`请判断这句话的情绪状态，并使用{情绪:#}` 的格式返回

openai 的 api 中提供了 function calling 的调用方法，可以保证在返回时格式和参数的正确性，对于需要返回特定格式，如 json 的情况下尤为好用。

“**多模态角色——AIGC 标准件”**

如果要找出一个在大众游戏类型中普遍适用的标准模块的话，NPC 是一个可以被准确描述的标准组件。上文中提到的 AIGC 视频游戏中，绝大多数都支持了 NPC 的语音输出和动画表现。此外情绪控制、记忆能力则也成为 NPC 驱动的标准能力，这是区别于传统角色的绝好实践。

使用前文介绍的类似的标准提示词驱动接口通过动画状态机可接收的参数来驱动角色的动画系统。

![](/static/images/k1/UMhYb6w9joXtHjxo5aTcj5U2nHe.png)

角色记忆在用户的体验中至关重要，他决定了智能体应该知道哪些东西并用于从中产生新的联想和决策。例如你告诉一名销售 NPC 超市缺少某种口味的饮料后，那么他可以在第二天的规划时将“向超市销售某重口味的饮料”作为其执行计划。

当然实际情况并没有上述例子那么简单，由于记忆的复杂机制，我们需要对不同的记忆加以区分，以让 NPC 达到更好的决策效果。

在斯坦福的西部小镇中，介绍了基于“评价-衰减-压缩”的方式对记忆进行规划。

![](/static/images/k1/LRoBbrsfxom8LPxjOODckUZcnBc.png)

评价记忆可以设计重要性，相关性等维度。通过生活中的先验常识来对记忆的重要性和相关性进行量化评价。基于稀有事件的重要性一定要比经常发生的事件大这一目标设计提示词。(比如今天太阳从西边出来的稀有度一定比今天是晴天大很多，那么其重要性的数值也会较大。)

相关性维度可以从角色的设定中进行类比，比如作为销售员的职业更加关心客户和销售线索的信息，而不太关注农场里发生的事情。

记忆的衰减模拟了人记忆的特性，即随着时间的增加记忆被逐渐遗忘。设计记忆的衰减系数来模拟着这样的情况，越是衰减严重的记忆越难被召回(retrieval)。

所有的记忆维度组合起来可以形成召回(retrieval)参数用于在某次行为前作为搜索的参考依据。

记忆可以模仿长短期记忆那样通过经常召回成为角色的长期记忆保留下来作为之后行为和规划的指导，而不重要的短期记忆则会被压缩保留。

而得益于能力大模型的文本理解能力，上述这些操作均可以通过提示词来完成。

记忆数据类型在接收来自不同系统的数据时形式比较丰富，例如角色的知识、技能、与他人的关系、新的消息、状态、地理方位等等... 这些在过去的开发中我们习惯于分门别类地进行存储和处理，但对于大模型来说在获得足够多相关的记忆后才能获得较好的决策结果。像日志一样收集所有这些信息并且交由 vector database 或其他存储方式进行存储，大模型可以通过阅读这些日志并挑选它感兴趣的内容进行使用。

通过对记忆的处理，形成感知-计划-反思-行为的闭环。

![](/static/images/k1/CDmvbdq45obcfrx6oshcThU5nLh.png)

“**规则器——智能体的业务逻辑**”

不同的游戏中需要利用 AI 完成的任务大相径庭，难以包含一个普适的设计模块，根据与系统的边界大致分为两种类型。我把这两种类型称之为是 embedding 模式和 full-stack 模式。

**embedding 模式**

不难理解，是将生成式智能体对象作为一套相对独立的系统发挥作用。

例如其可能是充当翻译者和判定者的角色，用来将某种模糊的伤害描述程度翻译成特定数值的能力。

`给对方造成了巨量伤害` 那么伤害具体是多少则交由大模型进行判定，而输出的结果有可能是 `减少 500HP`。

另一个例子作为判定输出而的生成新的开放式事件或对象的能力，例如：

`一个见习魔法师将青蛙和鼻涕混合将会产生什么。` 输出的结果不受到预设内容的控制增加了游戏的趣味性。

而另一种常见情况则是受约束的规则器，它通常需要 AI 在多个已知的结果中选择一个合适的选择来保证不越过系统的边界，例如一位火枪手所能装备的武器只有左轮手枪和猎枪时，不应让 AI 产生“加特林机枪”这一选项。通过使用如：

`根据状态选择，{1:左轮手枪}，{2:猎枪}，并输出你选择的对象序号` 来完成输出以避免产生不符合系统合法值的内容。

**full-stack 模式**

顾名思义，full-stack 中 AI 包含了游戏中所有规则和机制，由于没有既有系统的边界限制，因此适合于自由度更高的类型。例如在文字解谜游戏中，full-stack 可以同时用来生成谜题，处理玩家反馈和生成新的谜题或者给出线索等多种功能。

编写这种模式的游戏时需要将完整的游戏流程设计好并转化成提示词，所得到的提示词中将包含背景、规则、范围等的内容。

full-stack 模式中的 Action 中的一个常用实践是生成场景图，通过对上下文的理解能力，可以通过 Dall.E 或者是 Midjourney 等工具绘制符合场景设定的图片。这样做虽然聪明但也是不得不取舍的事情，毕竟游戏逻辑和 3D 资产开发相对来说没有图片生成简单，但是通过 PCG 或者是 3D 对象生成的方式产生新的关卡，目前来看也没有想象中的复杂，甚至可以在几个月内看到纯 AI 生成的游戏面世。

虽然短期内在体验上还无法构成对传统游戏的挑战，但是在可预见的未来将会有越来越多这样的探索。例如在冒险游戏中生成场景地图时，AI 可以通过调用类似 Dell.E 的方式调用 InteliMap 在场景中实时创建可以交互的地图。类似的能力同样也可以扩展到 3D 场景和其他系统的实践中。到那时作为开发者便无需再设计细节，只需要提供简单的创意用户就可以体验到丰富的玩法。

**基础系统结构**

这里我们实现了一个基本的 3D 模拟小镇的效果，这里每个村民拥有自己的职业设定，并且房间通过自然语言的描述使用 PCG 工具创建出来。角色初期将探索场景，并且学习自己可以做哪些事情。角色在初始阶段被设定了一个目标，通过目标和习得的技能，角色规划自己的工作来达成每日的目标。

![](/static/images/k1/KRrSbYocDo89GrxWA6Hc5UMDn8e.png)

游戏包含了**游戏客户端、游戏服务器**以及 **LLM 推理服务**和一个**向量数据库，**如下图所示：

其中游戏客户端为单机客户端，每个客户端中只维护当前关卡的状态而不会同步其他客户端的状态信息。客户端运行时，向服务器发送请求指令来获取事件、获取对话信息等；游戏服务器则会根据客户端请求的内容和当前游戏对象的状态来推理事件、处理游戏逻辑等，并返回游戏客户端中游戏对象所需要展现的内容或指令；当服务器返回指令时，由客户端中的游戏对象负责具体呈现，例如角色执行事件和与其他角色交互对话。

游戏服务器中统一维护了各个游戏客户端的状态，并使用向量数据库对游戏对象的记忆等内容进行存储和管理；当需要对事件或内容进行决策和生成时，通过使用 LLM 推理服务来获取推理结果；推理完成后同时根据执行的结果更新关卡中相应的游戏对象状态和记忆等。

游戏的总体框架如下图所示：

**从抽象事件中学会对事件分层**

当角色规划了一个意图化的行为例如：“吃饭”时，这意图由于太过抽象而无法在场景中实际执行。达成意图时，我们可以借鉴 Voyager 中的设计思路，让角色在为了达成自己目标的进行学习和规划。

![](/static/images/k1/VffqbAlh2oet3tx40uUcPAzHncc.png)

如图，我们首先创建规划事件，如“吃饭”，随后根据吃饭这一规划搜索场景中所有可能执行的行为，我们称之为“二级事件”，如去冰箱取吃的，或者点外卖等，二级事件规划完成后开始执行事件的表现，如：走到冰箱-> 打开冰箱-> 取出食物-> 找椅子坐下-> 开始吃东西... 期间如果表现事件执行失败则会搜索其他可执行的事件，彻底失败后重新尝试进行下一次规划。

![](/static/images/k1/LWYjbNmOSou3YmxEKMAcL5D0nNc.png)

# 四、**面临的挑战**

目前在生成式 AI 的使用中，API 调用的费用依然占据很大一部分，而智能体在游戏 Gameplay 中驱动的调用则需要消耗大量的 token，而随着用户上涨 token 的消耗也将同比例上涨，也就意味着不存在成本的编辑递减。这对于想要盈利的小成本游戏开发者来说是个巨大的开销，所以更多的开发者将宁愿选择自己写逻辑。

另外引入 LLM 调用和提示词增加了整个系统的复杂度，在没有明确的“面向 AI 的设计模式”的指导下，开发者如何定义一套同时对 AI 和数值判定系统同时生效的也需要大量的实践，特别是在开发具有多个子系统，需要进行物理交互和跨系统的复杂数据读写的情况下更是令人为难。

此外，由于大模型输出的不确定可能需要为系统引入额外的 validation 层，用于检查模型输出的准确性。如果你的系统对模型的幻觉问题不能容忍，并且对输出的准确性要求极高，那么使用大语言模型的使用成本和开发成本都会极高，很可能不使用才是一了百了的最好办法。

但相信随着技术的发展，调用成本将会被无限摊薄。另外 AIPC 和 AI 收集的普及使得游戏内本地部署的小模型进行推理似乎也成为另一种选择，根据技术发展的历史规律来看，在基础设施充分普及的某个时间点必然会迎来 AI 游戏应用的爆发时刻。作为独立开发者需要做的，则是持续保持对前沿技术的判断力和虚心求知的良好心态，然后静待未来的到来。
